{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import percentileofscore\n",
    "\n",
    "# Load the dataset\n",
    "file_path = './archive-2/02-14-2018.csv'\n",
    "\n",
    "# Function to calculate metrics for a chunk\n",
    "def calculate_forward_only_metrics(chunk, all_flow_durations):\n",
    "    metrics = {}\n",
    "    total_flow_duration = chunk['Flow Duration'].sum()\n",
    "    metrics['Total_Flow_Duration_Percentile'] = percentileofscore(all_flow_durations, total_flow_duration)  # Percentile rank\n",
    "    metrics['Avg_Tot_Fwd_Pkts'] = chunk['Tot Fwd Pkts'].mean()  # Average forward packets\n",
    "    metrics['Total_Hits_All_Ports'] = chunk['Dst Port'].value_counts().sum()  # Total hits across all ports\n",
    "    metrics['Unique_Ports'] = chunk['Dst Port'].nunique()  # Number of unique ports\n",
    "    metrics['Port_Hit_Variance'] = chunk['Dst Port'].value_counts().var()  # Variance in hits across ports\n",
    "    return metrics\n",
    "\n",
    "# Function to generate a summary from updated metrics\n",
    "def generate_summary(metrics):\n",
    "    text = (\n",
    "        f\"{metrics['Total_Flow_Duration_Percentile']:.2f}, \"\n",
    "        f\"{metrics['Avg_Tot_Fwd_Pkts']:.2f}, \"\n",
    "        f\" {metrics['Total_Hits_All_Ports']}, \"\n",
    "        f\"{metrics['Unique_Ports']} \"\n",
    "       \n",
    "    )\n",
    "    return text\n",
    "\n",
    "try:\n",
    "    # Step 1: Load and preprocess the data\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # Convert Timestamp column to datetime\n",
    "    data['Timestamp'] = pd.to_datetime(data['Timestamp'], errors='coerce', format='%d/%m/%Y %H:%M:%S')\n",
    "    data = data.dropna(subset=['Timestamp'])  # Remove rows with invalid Timestamps\n",
    "\n",
    "    # Filter out rows where the label isn't \"Benign\"\n",
    "    if 'Label' in data.columns:\n",
    "        data = data[data['Label'] == 'Benign']\n",
    "    else:\n",
    "        raise ValueError(\"The dataset does not contain a 'Label' column. Cannot filter for Benign data.\")\n",
    "\n",
    "    # Exclude rows with zero byte values\n",
    "    data = data[(data['TotLen Fwd Pkts'] > 0) | (data['TotLen Bwd Pkts'] > 0)]\n",
    "\n",
    "    # Create time-based chunks (5 seconds with 50% overlap)\n",
    "    data['Timestamp_Seconds'] = (data['Timestamp'].astype('int64') // 1e9).astype(int)\n",
    "    chunk_start = (data['Timestamp_Seconds'] // 5) * 5\n",
    "    data['Chunk Start'] = chunk_start\n",
    "\n",
    "    # Extract all total flow durations for percentile computation\n",
    "    all_total_flow_durations = [\n",
    "        data[data['Chunk Start'] == start]['Flow Duration'].sum()\n",
    "        for start in data['Chunk Start'].unique()\n",
    "    ]\n",
    "\n",
    "    # Step 2: Process overlapping 5-second chunks\n",
    "    chunk_results = []\n",
    "    chunk_ids = data['Chunk Start'].unique()\n",
    "\n",
    "    for start in chunk_ids:\n",
    "        chunk_data = data[data['Chunk Start'] == start]\n",
    "        if not chunk_data.empty:\n",
    "            # Calculate metrics\n",
    "            metrics = calculate_forward_only_metrics(chunk_data, all_total_flow_durations)\n",
    "            metrics['Chunk_ID'] = start  # Add chunk identifier for reference\n",
    "            \n",
    "            # Generate summary text\n",
    "            summary_text = generate_summary(metrics)\n",
    "            chunk_results.append({'Chunk ID': start, 'Summary': summary_text})\n",
    "\n",
    "    # Step 3: Convert results to a DataFrame\n",
    "    chunk_summary_df = pd.DataFrame(chunk_results)\n",
    "\n",
    "    # Save the results to a CSV file\n",
    "    output_file = './chunk_numeric1.csv'\n",
    "    chunk_summary_df.to_csv(output_file, index=False)\n",
    "\n",
    "    print(f\"Summaries for overlapping 5-second chunks with percentiles have been saved to {output_file}.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {file_path}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    exit()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
